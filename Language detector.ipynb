{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f66d4889",
   "metadata": {},
   "source": [
    "# Language detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65053be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bad09f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:/Users/Kishlay kumar/Downloads/sentences.csv', on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75eaf739",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\Kishlay kumar\\Downloads\\sentences.csv',\n",
    "                            sep='\\t', \n",
    "                            encoding='utf8', \n",
    "                            index_col=0,\n",
    "                            names=['lang','text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c9b32d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cmn</td>\n",
       "      <td>我們試試看！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cmn</td>\n",
       "      <td>我该去睡觉了。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cmn</td>\n",
       "      <td>你在干什麼啊？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cmn</td>\n",
       "      <td>這是什麼啊？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cmn</td>\n",
       "      <td>今天是６月１８号，也是Muiriel的生日！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11229419</th>\n",
       "      <td>dan</td>\n",
       "      <td>Hvorfor er du så dum?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11229420</th>\n",
       "      <td>dan</td>\n",
       "      <td>Hvorfor er I så dumme?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11229421</th>\n",
       "      <td>epo</td>\n",
       "      <td>Kial vi estas tiel stultaj?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11229422</th>\n",
       "      <td>spa</td>\n",
       "      <td>En fin la gente se envidia por cosas muy tontas.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11229423</th>\n",
       "      <td>eng</td>\n",
       "      <td>Anyways, people get jealous over stupid stuff.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10773949 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         lang                                              text\n",
       "1         cmn                                            我們試試看！\n",
       "2         cmn                                           我该去睡觉了。\n",
       "3         cmn                                           你在干什麼啊？\n",
       "4         cmn                                            這是什麼啊？\n",
       "5         cmn                            今天是６月１８号，也是Muiriel的生日！\n",
       "...       ...                                               ...\n",
       "11229419  dan                             Hvorfor er du så dum?\n",
       "11229420  dan                            Hvorfor er I så dumme?\n",
       "11229421  epo                       Kial vi estas tiel stultaj?\n",
       "11229422  spa  En fin la gente se envidia por cosas muy tontas.\n",
       "11229423  eng    Anyways, people get jealous over stupid stuff.\n",
       "\n",
       "[10773949 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4a50cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_cond = [True if 20<=len(s)<=200 else False for s in data['text']]\n",
    "data = data[len_cond]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f3c014d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cmn</td>\n",
       "      <td>今天是６月１８号，也是Muiriel的生日！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cmn</td>\n",
       "      <td>选择什么是“对”或“错”是一项艰难的任务，我们却必须要完成它。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>cmn</td>\n",
       "      <td>我们看东西不是看其实质，而是以我们的主观意识看它们的。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>cmn</td>\n",
       "      <td>生活就是當你忙著進行你的計劃時總有其他的事情發生。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>deu</td>\n",
       "      <td>Lass uns etwas versuchen!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11229419</th>\n",
       "      <td>dan</td>\n",
       "      <td>Hvorfor er du så dum?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11229420</th>\n",
       "      <td>dan</td>\n",
       "      <td>Hvorfor er I så dumme?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11229421</th>\n",
       "      <td>epo</td>\n",
       "      <td>Kial vi estas tiel stultaj?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11229422</th>\n",
       "      <td>spa</td>\n",
       "      <td>En fin la gente se envidia por cosas muy tontas.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11229423</th>\n",
       "      <td>eng</td>\n",
       "      <td>Anyways, people get jealous over stupid stuff.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9060619 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         lang                                              text\n",
       "5         cmn                            今天是６月１８号，也是Muiriel的生日！\n",
       "21        cmn                   选择什么是“对”或“错”是一项艰难的任务，我们却必须要完成它。\n",
       "67        cmn                       我们看东西不是看其实质，而是以我们的主观意识看它们的。\n",
       "71        cmn                         生活就是當你忙著進行你的計劃時總有其他的事情發生。\n",
       "77        deu                         Lass uns etwas versuchen!\n",
       "...       ...                                               ...\n",
       "11229419  dan                             Hvorfor er du så dum?\n",
       "11229420  dan                            Hvorfor er I så dumme?\n",
       "11229421  epo                       Kial vi estas tiel stultaj?\n",
       "11229422  spa  En fin la gente se envidia por cosas muy tontas.\n",
       "11229423  eng    Anyways, people get jealous over stupid stuff.\n",
       "\n",
       "[9060619 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c53d6814",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = ['deu', 'eng', 'fra', 'ita', 'por', 'spa']\n",
    "data = data[data['lang'].isin(lang)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68e1bc9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>deu</td>\n",
       "      <td>Lass uns etwas versuchen!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>deu</td>\n",
       "      <td>Ich muss schlafen gehen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>deu</td>\n",
       "      <td>Heute ist der 18. Juni und das ist der Geburts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>deu</td>\n",
       "      <td>Herzlichen Glückwunsch zum Geburtstag, Muiriel!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>deu</td>\n",
       "      <td>Muiriel ist jetzt 20.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11229415</th>\n",
       "      <td>spa</td>\n",
       "      <td>¿Me esperará mañana?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11229416</th>\n",
       "      <td>spa</td>\n",
       "      <td>¿Me va a esperar mañana?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11229418</th>\n",
       "      <td>spa</td>\n",
       "      <td>Nos mataste con tus historias.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11229422</th>\n",
       "      <td>spa</td>\n",
       "      <td>En fin la gente se envidia por cosas muy tontas.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11229423</th>\n",
       "      <td>eng</td>\n",
       "      <td>Anyways, people get jealous over stupid stuff.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3971166 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         lang                                               text\n",
       "77        deu                          Lass uns etwas versuchen!\n",
       "78        deu                           Ich muss schlafen gehen.\n",
       "81        deu  Heute ist der 18. Juni und das ist der Geburts...\n",
       "82        deu    Herzlichen Glückwunsch zum Geburtstag, Muiriel!\n",
       "83        deu                              Muiriel ist jetzt 20.\n",
       "...       ...                                                ...\n",
       "11229415  spa                               ¿Me esperará mañana?\n",
       "11229416  spa                           ¿Me va a esperar mañana?\n",
       "11229418  spa                     Nos mataste con tus historias.\n",
       "11229422  spa   En fin la gente se envidia por cosas muy tontas.\n",
       "11229423  eng     Anyways, people get jealous over stupid stuff.\n",
       "\n",
       "[3971166 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca73c020",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trim = pd.DataFrame(columns=['lang','text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "875ad839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [lang, text]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_trim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fbd614d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kishlay kumar\\AppData\\Local\\Temp\\ipykernel_17280\\925054039.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_trim = data_trim.append(lang_trim)\n",
      "C:\\Users\\Kishlay kumar\\AppData\\Local\\Temp\\ipykernel_17280\\925054039.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_trim = data_trim.append(lang_trim)\n",
      "C:\\Users\\Kishlay kumar\\AppData\\Local\\Temp\\ipykernel_17280\\925054039.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_trim = data_trim.append(lang_trim)\n",
      "C:\\Users\\Kishlay kumar\\AppData\\Local\\Temp\\ipykernel_17280\\925054039.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_trim = data_trim.append(lang_trim)\n",
      "C:\\Users\\Kishlay kumar\\AppData\\Local\\Temp\\ipykernel_17280\\925054039.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_trim = data_trim.append(lang_trim)\n",
      "C:\\Users\\Kishlay kumar\\AppData\\Local\\Temp\\ipykernel_17280\\925054039.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_trim = data_trim.append(lang_trim)\n"
     ]
    }
   ],
   "source": [
    "for l in lang:\n",
    "    lang_trim = data[data['lang'] ==l].sample(50000,random_state = 100)\n",
    "    data_trim = data_trim.append(lang_trim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "341ef06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10012920</th>\n",
       "      <td>deu</td>\n",
       "      <td>Sagt Tom, dass ich auf ihn zu Hause warte.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2761961</th>\n",
       "      <td>deu</td>\n",
       "      <td>Eine eigene Meinung ist ein Luxus, den sich ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911708</th>\n",
       "      <td>deu</td>\n",
       "      <td>Warten wir, bis wir dran sind!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368528</th>\n",
       "      <td>deu</td>\n",
       "      <td>Er war furchtbar beunruhigt, als er jene Gesch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059859</th>\n",
       "      <td>deu</td>\n",
       "      <td>Mein lieber Freund, ich bin zu dem geworden, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5769332</th>\n",
       "      <td>spa</td>\n",
       "      <td>No estaremos aquí a partir de las dos y media.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496876</th>\n",
       "      <td>spa</td>\n",
       "      <td>Tom vino a mi oficina esta mañana.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413403</th>\n",
       "      <td>spa</td>\n",
       "      <td>Entonces llegó la vecina, que se puso a gritar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170543</th>\n",
       "      <td>spa</td>\n",
       "      <td>¿Estás seguro de que no te olvidaste de nada?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745352</th>\n",
       "      <td>spa</td>\n",
       "      <td>Tengo que recoger algunas flores.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         lang                                               text\n",
       "10012920  deu         Sagt Tom, dass ich auf ihn zu Hause warte.\n",
       "2761961   deu  Eine eigene Meinung ist ein Luxus, den sich ni...\n",
       "2911708   deu                     Warten wir, bis wir dran sind!\n",
       "368528    deu  Er war furchtbar beunruhigt, als er jene Gesch...\n",
       "2059859   deu  Mein lieber Freund, ich bin zu dem geworden, w...\n",
       "...       ...                                                ...\n",
       "5769332   spa     No estaremos aquí a partir de las dos y media.\n",
       "1496876   spa                 Tom vino a mi oficina esta mañana.\n",
       "2413403   spa  Entonces llegó la vecina, que se puso a gritar...\n",
       "5170543   spa      ¿Estás seguro de que no te olvidaste de nada?\n",
       "1745352   spa                  Tengo que recoger algunas flores.\n",
       "\n",
       "[300000 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_trim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb6679f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shuffle = data_trim.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86a5ddcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2105924</th>\n",
       "      <td>por</td>\n",
       "      <td>Falou-se de literatura.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6810135</th>\n",
       "      <td>ita</td>\n",
       "      <td>Non sono sicura di aver tradotto correttamente...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004398</th>\n",
       "      <td>por</td>\n",
       "      <td>O menino usa óculos.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8897575</th>\n",
       "      <td>ita</td>\n",
       "      <td>Non mi lascerà aiutarlo.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380229</th>\n",
       "      <td>fra</td>\n",
       "      <td>Nous sommes en bonne santé.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4031223</th>\n",
       "      <td>por</td>\n",
       "      <td>Isso é o que chamamos amor verdadeiro.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8564265</th>\n",
       "      <td>por</td>\n",
       "      <td>De que forma eu posso te ajudar hoje?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8539120</th>\n",
       "      <td>por</td>\n",
       "      <td>Eu não acredito no que o Tom me disse.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6172786</th>\n",
       "      <td>ita</td>\n",
       "      <td>È urgente che lo veda.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3482508</th>\n",
       "      <td>deu</td>\n",
       "      <td>Wie schätzen Sie die Situation in der Region ein?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lang                                               text\n",
       "2105924  por                            Falou-se de literatura.\n",
       "6810135  ita  Non sono sicura di aver tradotto correttamente...\n",
       "1004398  por                               O menino usa óculos.\n",
       "8897575  ita                           Non mi lascerà aiutarlo.\n",
       "380229   fra                        Nous sommes en bonne santé.\n",
       "...      ...                                                ...\n",
       "4031223  por             Isso é o que chamamos amor verdadeiro.\n",
       "8564265  por              De que forma eu posso te ajudar hoje?\n",
       "8539120  por             Eu não acredito no que o Tom me disse.\n",
       "6172786  ita                             È urgente che lo veda.\n",
       "3482508  deu  Wie schätzen Sie die Situation in der Region ein?\n",
       "\n",
       "[300000 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "049c06ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_shuffle[0:210000]\n",
    "valid = data_shuffle[210000:270000]\n",
    "test = data_shuffle[270000:300000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7834e0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3162122</th>\n",
       "      <td>eng</td>\n",
       "      <td>I think Tom doesn't want our help.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6301522</th>\n",
       "      <td>ita</td>\n",
       "      <td>Puoi svegliarla per me?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11166463</th>\n",
       "      <td>fra</td>\n",
       "      <td>Je pense que tu es le seul à t'en soucier.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7698961</th>\n",
       "      <td>fra</td>\n",
       "      <td>Tom l'a fait tout seul.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5679149</th>\n",
       "      <td>eng</td>\n",
       "      <td>We've put the Christmas presents under the tree.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4031223</th>\n",
       "      <td>por</td>\n",
       "      <td>Isso é o que chamamos amor verdadeiro.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8564265</th>\n",
       "      <td>por</td>\n",
       "      <td>De que forma eu posso te ajudar hoje?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8539120</th>\n",
       "      <td>por</td>\n",
       "      <td>Eu não acredito no que o Tom me disse.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6172786</th>\n",
       "      <td>ita</td>\n",
       "      <td>È urgente che lo veda.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3482508</th>\n",
       "      <td>deu</td>\n",
       "      <td>Wie schätzen Sie die Situation in der Region ein?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         lang                                               text\n",
       "3162122   eng                 I think Tom doesn't want our help.\n",
       "6301522   ita                            Puoi svegliarla per me?\n",
       "11166463  fra         Je pense que tu es le seul à t'en soucier.\n",
       "7698961   fra                            Tom l'a fait tout seul.\n",
       "5679149   eng   We've put the Christmas presents under the tree.\n",
       "...       ...                                                ...\n",
       "4031223   por             Isso é o que chamamos amor verdadeiro.\n",
       "8564265   por              De que forma eu posso te ajudar hoje?\n",
       "8539120   por             Eu não acredito no que o Tom me disse.\n",
       "6172786   ita                             È urgente che lo veda.\n",
       "3482508   deu  Wie schätzen Sie die Situation in der Region ein?\n",
       "\n",
       "[30000 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68d7d699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "def get_trigrams(corpus,n_feat=200):\n",
    "    \"\"\"\n",
    "    Returns a list of the N most common character trigrams from a list of sentences\n",
    "    params\n",
    "    ------------\n",
    "        corpus: list of strings\n",
    "        n_feat: integer\n",
    "    \"\"\"\n",
    "    \n",
    "    #fit the n-gram model\n",
    "    vectorizer = CountVectorizer(analyzer='char',\n",
    "                            ngram_range=(3, 3)\n",
    "                            ,max_features=n_feat)\n",
    "    \n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    \n",
    "    #Get model feature names\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    \n",
    "    return feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c098323",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kishlay kumar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'olt': 0, 'un ': 1, 'n v': 2, 'ndo': 3, 'esp': 4, 'hac': 5, 'ent': 6, 'a v': 7, 'oro': 8, ' th': 9, 'm a': 10, 'a d': 11, 'at.': 12, ' ha': 13, 'r d': 14, ', w': 15, ' nã': 16, 'ría': 17, 's n': 18, 'una': 19, 'car': 20, ' vi': 21, 'hey': 22, 'fai': 23, 'das': 24, 't d': 25, 'hat': 26, \"'es\": 27, 'um ': 28, 'em ': 29, 'ce ': 30, ' si': 31, 's m': 32, 'wer': 33, 'thi': 34, \"n't\": 35, 'str': 36, 'ne ': 37, 'can': 38, 'ouv': 39, 'ht ': 40, 'o n': 41, 'o a': 42, 'a e': 43, 'ung': 44, 'ade': 45, 'ly ': 46, 'plu': 47, 'del': 48, ' he': 49, 'mit': 50, 'a t': 51, 'ner': 52, 'of ': 53, 'und': 54, 'nno': 55, 'ues': 56, 'wie': 57, ' dé': 58, 'ano': 59, 'ine': 60, 'ère': 61, 'tom': 62, 'wit': 63, ' é ': 64, 'aci': 65, 'ink': 66, 'voi': 67, 'o p': 68, 'sso': 69, 'osa': 70, ', d': 71, 's p': 72, 'anc': 73, 'er.': 74, 'jou': 75, 'her': 76, 'ión': 77, 'e w': 78, ' sc': 79, 's e': 80, 'uie': 81, 'ace': 82, 'tie': 83, 'ige': 84, 'eit': 85, 'hin': 86, ' of': 87, ' as': 88, 'ary': 89, 's q': 90, 'a l': 91, 'ain': 92, 'tem': 93, 'ren': 94, 'i a': 95, ' ri': 96, 'ué ': 97, 'son': 98, 'r l': 99, ' de': 100, 'ia.': 101, 'es.': 102, 'aid': 103, 'sai': 104, 'ann': 105, 'ai ': 106, ' kn': 107, 'ous': 108, ' o ': 109, 'mui': 110, 'oir': 111, 'lo ': 112, 'th ': 113, 'ui ': 114, 'der': 115, 'ans': 116, 'ica': 117, 'ese': 118, 'sic': 119, 'for': 120, 'm s': 121, 'o s': 122, 's i': 123, 'i d': 124, ' go': 125, 'n p': 126, 'ies': 127, 'ant': 128, 'o t': 129, 'los': 130, ' il': 131, 'ass': 132, 'des': 133, 'ett': 134, ' ma': 135, 'es ': 136, ' pl': 137, 'm i': 138, 'ia ': 139, ' su': 140, 'e e': 141, 'ell': 142, 'h h': 143, 'tra': 144, 'ido': 145, 't w': 146, 'ete': 147, 'm p': 148, 'you': 149, ' um': 150, 'n a': 151, 's a': 152, 'a m': 153, 'por': 154, ' hi': 155, 'did': 156, 'd h': 157, 'eu ': 158, 's s': 159, 'ehr': 160, \"'s \": 161, 'dos': 162, 'di ': 163, 'm e': 164, 'a i': 165, 'y w': 166, ' em': 167, ' ka': 168, 'not': 169, ' un': 170, 'nte': 171, 'ot ': 172, ' fa': 173, 'nho': 174, 'hav': 175, \"j'a\": 176, 'e d': 177, 'd t': 178, ' av': 179, ' i ': 180, 'faz': 181, 'est': 182, 'our': 183, 'ith': 184, 't p': 185, 'ehe': 186, 'n h': 187, 've ': 188, 'tu ': 189, 'is ': 190, ' er': 191, 't m': 192, 'de ': 193, 'os ': 194, 'rie': 195, 'pou': 196, ' ni': 197, 'e, ': 198, 'ria': 199, 'ela': 200, 'ra ': 201, 'ons': 202, ' ih': 203, 'u a': 204, 'ang': 205, 'qué': 206, 'omm': 207, 'r w': 208, 'ess': 209, 'enn': 210, 'nt ': 211, 'ma ': 212, 'con': 213, 'she': 214, 'e a': 215, 'ito': 216, 'e i': 217, 'abe': 218, 'pas': 219, 'ux ': 220, 'al ': 221, \"'t \": 222, 'sen': 223, 'st ': 224, 'cê ': 225, 'r t': 226, 'ene': 227, 'r i': 228, 'zu ': 229, 'pue': 230, 'ora': 231, 'hab': 232, 'ich': 233, 'une': 234, 'nen': 235, 'hre': 236, 'tio': 237, ' so': 238, 'ist': 239, 'now': 240, 'die': 241, 'ear': 242, 't t': 243, 'ns ': 244, 'ber': 245, 'do ': 246, 'nic': 247, 'mme': 248, 'les': 249, 'mai': 250, 'ele': 251, 't a': 252, 'd a': 253, 'ait': 254, 'ger': 255, 'ter': 256, 'ad ': 257, 'dan': 258, 'ado': 259, 'ía ': 260, 'as.': 261, 'lte': 262, 'res': 263, ' et': 264, 'n t': 265, 'ow ': 266, 'e j': 267, 'e o': 268, 'to.': 269, 'io ': 270, 'nos': 271, 'ght': 272, 'ed ': 273, 'chi': 274, 'ava': 275, 'le ': 276, 's d': 277, 'n g': 278, 'che': 279, 'nde': 280, 'go ': 281, 'e b': 282, 'per': 283, 'den': 284, 'ue ': 285, 's l': 286, ' le': 287, 'll ': 288, ' en': 289, 'ien': 290, 'e l': 291, 'ein': 292, ' li': 293, 'far': 294, 'out': 295, \"dn'\": 296, 'min': 297, ' it': 298, ' me': 299, ' el': 300, 'cer': 301, 'a f': 302, 'y s': 303, 'ocê': 304, 'nou': 305, 'hou': 306, ' wa': 307, 'as ': 308, 'tte': 309, ' es': 310, 'las': 311, 'och': 312, 'n w': 313, 'tat': 314, ' ti': 315, 'rui': 316, 'us ': 317, 'e r': 318, 'uir': 319, 'rde': 320, ' ho': 321, ' eu': 322, ' ch': 323, ' fo': 324, 'air': 325, 'lei': 326, 'ost': 327, ' à ': 328, 'tha': 329, ' di': 330, 'uit': 331, 'te ': 332, 'nn ': 333, 'a c': 334, 'eur': 335, 'n d': 336, 't h': 337, 'sch': 338, \"l'a\": 339, 'or ': 340, 't e': 341, 'nti': 342, 'nge': 343, 'mos': 344, 'on ': 345, 're ': 346, 'ero': 347, 's c': 348, 'be ': 349, ' qu': 350, ' re': 351, 'o i': 352, 'i w': 353, 't o': 354, 'nha': 355, 'sie': 356, 'd m': 357, 'ure': 358, 'm c': 359, 'n b': 360, 'e v': 361, 'e n': 362, 'sei': 363, ' co': 364, ' wh': 365, 'ida': 366, 'pre': 367, 'va ': 368, 'gio': 369, 'onn': 370, ' pu': 371, 'r e': 372, 'g t': 373, 'o d': 374, 'end': 375, 'a p': 376, 't i': 377, 'ry ': 378, ' tr': 379, 'qua': 380, 'o f': 381, 'ti ': 382, 'eux': 383, ' va': 384, 'a n': 385, 'ste': 386, 'e t': 387, ' ic': 388, 'war': 389, 'was': 390, ' bi': 391, ' pi': 392, 'na ': 393, 'iam': 394, 'si ': 395, \"'ai\": 396, 'non': 397, ' e ': 398, 'dad': 399, ' mo': 400, 'inh': 401, 'uer': 402, 'ier': 403, ' se': 404, 'n s': 405, 'gli': 406, 'don': 407, 'i s': 408, 'não': 409, ' du': 410, 'la ': 411, 'rai': 412, 'o m': 413, 'n m': 414, 'tai': 415, ' è ': 416, 'an ': 417, 'ome': 418, 'uis': 419, 't s': 420, 'his': 421, 'kno': 422, 'er ': 423, 'a s': 424, 'más': 425, 'iel': 426, ' ca': 427, 'cht': 428, 'o q': 429, 'mar': 430, 'ou ': 431, 'all': 432, 'au ': 433, ' at': 434, 'ng ': 435, 'ued': 436, 'ens': 437, 'ali': 438, 'ez ': 439, 'e g': 440, 'se ': 441, 'i p': 442, 'ás ': 443, 'wei': 444, 'cha': 445, 'rec': 446, 'mei': 447, 'ch ': 448, ' is': 449, 'no ': 450, \" l'\": 451, 'ha ': 452, 'n, ': 453, 'do.': 454, 'tes': 455, 'tru': 456, 'aus': 457, 'y t': 458, ' lo': 459, 'nta': 460, 'wan': 461, 'mi ': 462, ' mi': 463, 'ebe': 464, 't, ': 465, 'tod': 466, 'nda': 467, 'm w': 468, 'ão ': 469, 'nd ': 470, 'e f': 471, 'to ': 472, 'hr ': 473, 'ihr': 474, 'am ': 475, 'uld': 476, 'aba': 477, 'pia': 478, ' ve': 479, ' in': 480, 'ta ': 481, 'man': 482, 'tou': 483, 'ke ': 484, 'uma': 485, 'auf': 486, 'ben': 487, ' do': 488, 'id ': 489, 'e m': 490, ' sh': 491, 'e h': 492, ' be': 493, 'su ': 494, 'ges': 495, 'ers': 496, \" d'\": 497, 'it ': 498, 'sta': 499, 'i i': 500, 'e s': 501, \"on'\": 502, 'rea': 503, 'ada': 504, ' sa': 505, ' ar': 506, 'je ': 507, 'r a': 508, 'ach': 509, 'ted': 510, 'era': 511, 'kei': 512, 'qui': 513, ' yo': 514, 're.': 515, 'tto': 516, 'tar': 517, 'vai': 518, 'el ': 519, 'o c': 520, 'ten': 521, ' on': 522, 'ire': 523, 'com': 524, 'wha': 525, ' la': 526, 'lic': 527, 'da ': 528, 'ei ': 529, 'so ': 530, 'sto': 531, ' zu': 532, 'n e': 533, ' st': 534, ' po': 535, 'du ': 536, ' fr': 537, 'ave': 538, \"sn'\": 539, ' bo': 540, 'zio': 541, 'ing': 542, 'en.': 543, 'i c': 544, 'eve': 545, 'he ': 546, ' to': 547, ' no': 548, 'par': 549, 'ate': 550, 'ld ': 551, 'lie': 552, \" n'\": 553, 'in ': 554, 'amo': 555, 'ut ': 556, ' al': 557, \"qu'\": 558, 'n i': 559, 'men': 560, ' ge': 561, 'e c': 562, 'ery': 563, 'voc': 564, 'ind': 565, 'ran': 566, 'me ': 567, 'oin': 568, 'one': 569, 'rei': 570, 'tan': 571, 'hte': 572, ' ét': 573, 'mon': 574, 'que': 575, ' pe': 576, 'wir': 577, 'li ': 578, 'lla': 579, 'n l': 580, 'hen': 581, 'r s': 582, ' da': 583, 'ey ': 584, 'ill': 585, 'sse': 586, 'tá ': 587, 'ais': 588, 'ro ': 589, ' we': 590, ' tu': 591, ' y ': 592, 'en ': 593, 'ono': 594, ' ne': 595, ' mu': 596, 'a a': 597, ' na': 598, 'ont': 599, 'os.': 600, 'cos': 601, ' an': 602, 'at ': 603, 'ho ': 604, 'lle': 605, 'and': 606, 'il ': 607, 'él ': 608, ' wo': 609, 'ert': 610, 'the': 611, ' je': 612, 'ern': 613, 'ion': 614, 'isc': 615, 'tro': 616, 'att': 617, 'nto': 618, 'ar ': 619, 'stá': 620, 'ort': 621, 'ver': 622, 'ur ': 623, 'en,': 624, ' ac': 625, 's t': 626, ' vo': 627, ' ei': 628, ' wi': 629, ' te': 630, 'mo ': 631, 'ois': 632, 'vou': 633, ' pr': 634, ' ta': 635, ' cu': 636, 'uch': 637, ' au': 638, ' fi': 639, 'ie ': 640, 'gen': 641, 'e p': 642, 'oi ': 643, ' pa': 644, 'om ': 645, 'sa ': 646, 'ara': 647, 'e q': 648, 'o l': 649, 'ss ': 650, 'ir ': 651, ' ce': 652, 't l': 653, 'oul': 654, 'are': 655, 'tre': 656, 'ere': 657, 'ato': 658, 'iss': 659, ' a ': 660, 'eme': 661, 'et ': 662, 'o e': 663}\n"
     ]
    }
   ],
   "source": [
    "#obtain trigrams from each language\n",
    "features = {}\n",
    "features_set = set()\n",
    "\n",
    "for l in lang:\n",
    "    \n",
    "    #get corpus filtered by language\n",
    "    corpus = train[train.lang==l]['text']\n",
    "    \n",
    "    #get 200 most frequent trigrams\n",
    "    trigrams = get_trigrams(corpus)\n",
    "#     print(trigrams)\n",
    "    \n",
    "    #add to dict and set\n",
    "    features[l] = trigrams \n",
    "#     print(features)\n",
    "    features_set.update(trigrams)\n",
    "#     print(features_set)\n",
    "    \n",
    "#create vocabulary list using feature set\n",
    "vocab = dict()\n",
    "for i,f in enumerate(features_set):\n",
    "    vocab[f]=i\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13d05bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        olt  un   n v  ndo  esp  hac  ent  a v  oro   th  ...  oul  are  tre  \\\n",
      "0         0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "1         0    0    0    0    0    0    1    0    0    0  ...    0    0    0   \n",
      "2         0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "3         0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "4         0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "209995    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "209996    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "209997    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "209998    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "209999    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "\n",
      "        ere  ato  iss   a   eme  et   o e  \n",
      "0         0    0    0    0    0    0    0  \n",
      "1         0    0    0    0    0    0    0  \n",
      "2         0    0    0    0    0    0    0  \n",
      "3         0    0    0    0    0    0    0  \n",
      "4         0    0    0    0    0    0    0  \n",
      "...     ...  ...  ...  ...  ...  ...  ...  \n",
      "209995    0    0    0    0    0    0    0  \n",
      "209996    0    0    0    0    0    0    0  \n",
      "209997    0    0    0    0    0    0    0  \n",
      "209998    0    0    0    0    0    0    0  \n",
      "209999    0    0    0    0    0    0    0  \n",
      "\n",
      "[210000 rows x 664 columns]\n"
     ]
    }
   ],
   "source": [
    "#train count vectoriser using vocabulary\n",
    "vectorizer = CountVectorizer(analyzer='char',\n",
    "                             ngram_range=(3, 3),\n",
    "                            vocabulary=vocab)\n",
    "\n",
    "#create feature matrix for training set\n",
    "corpus = train['text']   \n",
    "X = vectorizer.fit_transform(corpus)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "train_feat = pd.DataFrame(data=X.toarray(),columns=feature_names)\n",
    "print(train_feat)\n",
    "#Scale feature matrix \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fd25856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        olt  un   n v  ndo  esp  hac  ent  a v  oro   th  ...  are  tre  ere  \\\n",
      "0         0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "1         0    0    0    0    0    0    1    0    0    0  ...    0    0    0   \n",
      "2         0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "3         0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "4         0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "209995    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "209996    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "209997    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "209998    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "209999    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "\n",
      "        ato  iss   a   eme  et   o e  lang  \n",
      "0         0    0    0    0    0    0   por  \n",
      "1         0    0    0    0    0    0   ita  \n",
      "2         0    0    0    0    0    0   por  \n",
      "3         0    0    0    0    0    0   ita  \n",
      "4         0    0    0    0    0    0   fra  \n",
      "...     ...  ...  ...  ...  ...  ...   ...  \n",
      "209995    0    0    0    0    0    0   eng  \n",
      "209996    0    0    0    0    0    0   deu  \n",
      "209997    0    0    0    0    0    0   por  \n",
      "209998    0    0    0    0    0    0   deu  \n",
      "209999    0    0    0    0    0    0   spa  \n",
      "\n",
      "[210000 rows x 665 columns]\n"
     ]
    }
   ],
   "source": [
    "#Scale feature matrix \n",
    "train_min = train_feat.min()\n",
    "train_max = train_feat.max()\n",
    "# train_feat = (train_feat - train_min)/(train_max-train_min)\n",
    "\n",
    "#Add target variable \n",
    "train_feat['lang'] = list(train['lang'])\n",
    "print(train_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adaab7fe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#create feature matrix for validation set\n",
    "corpus = valid['text']   \n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "valid_feat = pd.DataFrame(data=X.toarray(),columns=feature_names)\n",
    "valid_feat = (valid_feat - train_min)/(train_max-train_min)\n",
    "valid_feat['lang'] = list(valid['lang'])\n",
    "\n",
    "#create feature matrix for test set\n",
    "corpus = test['text']   \n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "test_feat = pd.DataFrame(data=X.toarray(),columns=feature_names)\n",
    "test_feat = (test_feat - train_min)/(train_max-train_min)\n",
    "test_feat['lang'] = list(test['lang'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ed755e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create feature matrix for validation set\n",
    "# corpus = valid['text']   \n",
    "# X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# https://towardsdatascience.com/deep-neural-network-language-identification-ae1c158f6a7d\n",
    "\n",
    "# valid_feat = pd.DataFrame(data=X.toarray(),columns=feature_names)\n",
    "# valid_feat = (valid_feat - train_min)/(train_max-train_min)\n",
    "# valid_feat['lang'] = list(valid['lang'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c637ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "442f0c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install keras\n",
    "# from collections.abc import Iterable\n",
    "# pip install np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f86c358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35f51aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# from keras.utils import np_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "#Fit encoder\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(['deu', 'eng', 'fra', 'ita', 'por', 'spa'])\n",
    "\n",
    "def encode(y):\n",
    "    \"\"\"\n",
    "    Returns a list of one hot encodings\n",
    "    Params\n",
    "    ---------\n",
    "        y: list of language labels\n",
    "    \"\"\"\n",
    "    \n",
    "    y_encoded = encoder.transform(y)\n",
    "    y_dummy = np_utils.to_categorical(y_encoded)\n",
    "    \n",
    "    return y_dummy\n",
    "\n",
    "\n",
    "# # from keras.utils import np_utils\n",
    "# # import tensorflow as tf\n",
    "# from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ca16d3b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [42], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tf'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tf.keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "import tensorflow as tf\n",
    "# model = tf.keras.Sequential()\n",
    "\n",
    "#Get training data\n",
    "x = train_feat.drop('lang',axis=1)\n",
    "y = encode(train_feat['lang'])\n",
    "print(y)\n",
    "\n",
    "#Define model\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=663, activation='relu'))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#Train model\n",
    "model.fit(x, y, epochs=5, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7122d29c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [33], line 13\u001b[0m\n\u001b[0;32m      6\u001b[0m y_test \u001b[38;5;241m=\u001b[39m test_feat[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlang\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#Get predictions on test set\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# predict_x=model.predict(X_test) \u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# classes_x=np.argmax(predict_x,axis=1)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# labels = (model.predict(x_test) > 0.5).astype(\"int32\")\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# print(labels)\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(model\u001b[38;5;241m.\u001b[39mpredict(x_test), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(labels)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# classes_x=np.argmax(labels,axis=1)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "\n",
    "x_test = test_feat.drop('lang',axis=1)\n",
    "y_test = test_feat['lang']\n",
    "\n",
    "#Get predictions on test set\n",
    "# predict_x=model.predict(X_test) \n",
    "# classes_x=np.argmax(predict_x,axis=1)\n",
    "# labels = (model.predict(x_test) > 0.5).astype(\"int32\")\n",
    "# print(labels)\n",
    "labels = np.argmax(model.predict(x_test), axis=-1)\n",
    "print(labels)\n",
    "# classes_x=np.argmax(labels,axis=1)\n",
    "predictions = encoder.inverse_transform(labels)\n",
    "print(predictions)\n",
    "\n",
    "#Accuracy on test set\n",
    "accuracy = accuracy_score(y_test,predictions)\n",
    "print(accuracy)\n",
    "\n",
    "#Create confusion matrix\n",
    "lang = ['deu', 'eng', 'fra', 'ita', 'por', 'spa']\n",
    "conf_matrix = confusion_matrix(y_test,predictions)\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix,columns=lang,index=lang)\n",
    "\n",
    "#Plot confusion matrix heatmap\n",
    "plt.figure(figsize=(10, 10), facecolor='w', edgecolor='k')\n",
    "sns.set(font_scale=1.5)\n",
    "sns.heatmap(conf_matrix_df,cmap='coolwarm',annot=True,fmt='.5g',cbar=False)\n",
    "plt.xlabel('Predicted',fontsize=22)\n",
    "plt.ylabel('Actual',fontsize=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2562303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f72549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5102db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in lang:\n",
    "    \n",
    "    #get corpus filtered by language\n",
    "    corpus = train[train.lang==l]['text']\n",
    "    print(corpus)\n",
    "#     trigrams = get_trigrams(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bf0b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7290bff3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b626b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [' a ', ' al', ' ca', ' co', ' cu', ' de', ' di', ' el', ' en', ' es', ' ha', ' in', ' la', ' le', ' lo', ' ma', ' me', ' mi', ' mu', ' no', ' pa', ' pe', ' po', ' pr', ' pu', ' qu', ' re', ' sa', ' se', ' si', ' so', ' su', ' ta', ' te', ' ti', ' to', ' tr', ' un', ' ve', ' vi', ' y ', 'a a', 'a c', 'a d', 'a e', 'a l', 'a m', 'a n', 'a p', 'a s', 'a t', 'a v', 'aba', 'ace', 'aci', 'ada', 'ado', 'al ', 'an ', 'and', 'ant', 'ar ', 'ara', 'as ', 'as.', 'cer', 'com', 'con', 'da ', 'dad', 'de ', 'des', 'do ', 'do.', 'dos', 'e a', 'e c', 'e d', 'e e', 'e h', 'e l', 'e m', 'e n', 'e p', 'e q', 'e s', 'e t', 'el ', 'ell', 'en ', 'end', 'ene', 'ent', 'er ', 'era', 'ere', 'ero', 'es ', 'es.', 'esp', 'est', 'go ', 'hab', 'hac', 'ida', 'ido', 'ien', 'ier', 'ión', 'la ', 'las', 'le ', 'lla', 'lo ', 'los', 'mar', 'me ', 'men', 'mi ', 'mo ', 'mos', 'más', 'n a', 'n c', 'n e', 'n l', 'n p', 'na ', 'ndo', 'no ', 'nos', 'nta', 'nte', 'nto', 'o a', 'o c', 'o d', 'o e', 'o l', 'o m', 'o p', 'o q', 'o s', 'o t', 'om ', 'on ', 'or ', 'os ', 'os.', 'par', 'per', 'por', 'pre', 'pue', 'que', 'qui', 'r a', 'r e', 'ra ', 'ran', 're ', 'rec', 'res', 'ro ', 'ría', 's a', 's c', 's d', 's e', 's l', 's m', 's p', 's s', 'se ', 'sta', 'ste', 'sto', 'stá', 'su ', 'ta ', 'tan', 'tar', 'te ', 'ten', 'tie', 'to ', 'tod', 'tom', 'tra', 'tá ', 'ue ', 'ued', 'uer', 'uie', 'un ', 'una', 'ver', 'ás ', 'él ', 'ía ']\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc4890c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "816aec6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [43], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(tf\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# import tensorflow as tf\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tf'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf;print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d3ac86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778881c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b278dc3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd362b45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523aff36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a763ab85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
